# Programmazione Concorrente

[Return](./SistemiOperativi.md)

---

## Indice


---

## Introduzione

La programmazione concorrente è l'insieme delle tecniche, metodologie e strumenti per il supporto all'esecuzione di sistemi software composti da insiemi di attività svolte simultaneamente.

## Tipi di architettura:

### Single Processor

![alt text](image.png)

### Shared Memory Multiprocessor

![alt text](image-1.png)

Memoria interconnessa, ogni CPU può accedere ad ogni parte della ram.

## Sistemi Multiprocessore

**Classificazione**

- **UMA** (Uniform Memory Access) : Numero ridotto di processori, tempo di accesso alla memoria uniforme tra le CPU, una qualsiasi CPU una qualsiasi locazione di memoria.
- **NUMA** (Non Uniform Memory Access) : Ogni CPU ha parti di memoria vicine e lontane, la rete delle memorie è divisa gerarchicamnte per decongestionare il mezzo di connessione tra CPU e RAM.

### Distributed Memory Multiprocessor

![alt text](image-2.png)

Ogni CPU ha la sua memoria privata, mentre prima la memoria era condivisa.

**Due tipi**
- **MultiComputer**: nodi semplici (CPU, CACHE, RAM) e fisicamente vicini, in una stessa struttura interconnessi (CLUESTER, MASSIVELY PARALLEL COMPUTER).
- **Networks Systems**: nodi più complessi e fisicamente distanti

Oggi si hanno nodi con architettura multiprocessori, connessi tra loro con distributed memory.

## Tassonomia di Flynn

- **parallelismo a livello di istruzioni**
- **parallelismo a livello di dati**

![alt text](image-3.png)

- **SISD** (Single Instruction Single Data)
- **SIMD** (Single Instruction Multiple Data)
- **MISD** (Multiple Instruction Single Data)
- **MIMD** (Multiple Instruction Multiple Data)

## Tipi di Applicazioni

- **Multithreaded**: applicazioni strutturate come un insieme id processi
- **Multitasking/Distribuiti**: Le componenti dell'applicazione (task), sono eseguiti su nodi diversi
- **Parallele**: Eseguite su architetture ad elevato parallelismo, forte accoppiamento tra HW e SW a differenza delle altre due, è importante conoscere l'architettura HW per scrivere il SW. 

## Elaborazione non sequenziale

Necessaria per l'esecuzione di un processo non sequenziale

- **Elaborazione non sequenziale**: ovvero in grado di eseguire più operazioni contemporaneamente:

![alt text](image-4.png)

- Sistemi mutliprocessore VS sistemi monoprocessore (parallelismo gestito via SW)

-**Linguaggio di programmazione non sequenziale**: caratterizzato da una diversa granularità, ovvero la dimensione minima dell'unità di esecuzione.

## Interazione tra processi

Possibili forme di interazione tra processi concorrenti:

- **Cooperazione**: forma di interazione prevista e desiderata tradotto in scambio di infomrazioni tra processi
- **Competizione**: Interazione non desiderata, coordinamento dei processi nell'accesso a risorse condivise. Necessari meccaniscmi per regolare la competizione.
- **Interferenza**: Interazione causata da errori di programmazione, e.g. Deadlock

## Linguaggi per la programmazione concorrente

- Contengono costrutti per esprimedere moduli di programmi da eseguire come processi sequenziali distinti
- Contiene la possibiltà di esprimere quando un processo va attivato e terminato
- Contiene gli strumenti per specificare le interazioni tra i vari processi

